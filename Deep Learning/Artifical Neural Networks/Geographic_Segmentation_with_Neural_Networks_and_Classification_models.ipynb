{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Geographic Segmentation with Neural Networks and Classification models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Installing packages\n",
        "!pip install optuna"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sF10OEkWMWK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EkI59BX0vxP_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Preparing the data\n",
        "# Loading the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as F\n",
        "import optuna\n",
        "\n",
        "# Classification models\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "\n",
        "# Importing the data\n",
        "df = pd.read_csv('Data.csv')\n",
        "X = df.iloc[:, 3:-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "## Encoding the categorical data\n",
        "# Label encoding the \"Gender\" column\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2])\n",
        "\n",
        "# One-Hot Encoding the \"Geography\" column\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [1])],\n",
        "                       remainder = 'passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "# Split the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,\n",
        "                                                    random_state = 42)\n",
        "\n",
        "# Feature Scaling (a must for NN)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training the Classification models on Bag-of-words \n",
        "\n",
        "def list_classifiers():\n",
        "    classifiers = {\n",
        "        'Logistic Regression' : LogisticRegression(random_state = 42),\n",
        "        'K-Nearest Neighbors' : KNeighborsClassifier(n_neighbors = 5, p = 2, \n",
        "                                                     metric = 'minkowski'),\n",
        "        'Support Vector Machine' : SVC(kernel = 'linear', random_state = 42),\n",
        "        'Kernel SVM' : SVC(kernel = 'rbf', random_state = 42),\n",
        "        'Naive Bayes' : GaussianNB(),\n",
        "        'Decision Tree' : DecisionTreeClassifier(criterion = 'entropy', \n",
        "                                                 random_state = 42),\n",
        "        'Random Forest' : RandomForestClassifier(n_estimators=100, \n",
        "                                                 criterion='entropy',\n",
        "                                                 random_state = 42),\n",
        "    }\n",
        "    return classifiers\n",
        "\n",
        "# Get the classifiers\n",
        "classifiers = list_classifiers()\n",
        "score = {name : [] for name in list(classifiers)} \n",
        "for name, classifier in classifiers.items():\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  score[name].append(f1_score(y_test, y_pred))\n",
        "  score[name].append(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ml__NnUYMlv4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NN without HP tuning\n",
        "# Building the model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(F.Dense(units = 6, activation = 'relu')) # Input and first hidden layer\n",
        "model.add(F.Dense(units = 6, activation = 'relu')) # Second hidden layer\n",
        "model.add(F.Dense(units = 1, activation = 'sigmoid')) # Output layer\n",
        "\n",
        "# Training the model\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size = 32, epochs = 100, verbose = 0)\n",
        "\n",
        "# Predicting the test values\n",
        "y_pred = np.rint(model.predict(X_test))\n",
        "\n",
        "# f1 score and accuracy of predictions\n",
        "score['NN normal'] = [f1_score(y_test, y_pred), \n",
        "                 accuracy_score(y_test, y_pred)]"
      ],
      "metadata": {
        "id": "AXvYC8SJ0UwR",
        "cellView": "form"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Simple Optuna NN Tuner\n",
        "\n",
        "def objective(trial):\n",
        "  # Build the model\n",
        "  model = tf.keras.models.Sequential()\n",
        "  n_layers = trial.suggest_int(\"n_layers\", 1, 4)\n",
        "  for i in range(n_layers):\n",
        "      num_hidden = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128, log=True)\n",
        "      model.add(\n",
        "          F.Dense(\n",
        "              units = num_hidden,\n",
        "              activation = 'relu'\n",
        "          )\n",
        "      )\n",
        "  # Output layer\n",
        "  model.add(F.Dense(units = 1, activation = 'sigmoid'))\n",
        "  # Optimize the learning_rate for Adam optimizer    \n",
        "  lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr), \n",
        "                loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  \n",
        "  # Training the model\n",
        "  model.fit(X_train, y_train, batch_size = 32, epochs = 100, verbose = 0)\n",
        "  # Predicting the test values\n",
        "  y_pred = np.rint(model.predict(X_test))\n",
        "  # Calculating the scores\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  return accuracy\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\", \n",
        "                                study_name = 'Simple Optuna NN Tuning')\n",
        "    study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "zALiODFeMyAF",
        "outputId": "d24e24d4-7317-40b4-be32-8844ccfefacb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-04-06 09:34:01,597]\u001b[0m A new study created in memory with name: Simple Optuna NN Tuning\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:35:24,481]\u001b[0m Trial 0 finished with value: 0.8552 and parameters: {'n_layers': 4, 'n_units_l0': 41, 'n_units_l1': 79, 'n_units_l2': 9, 'n_units_l3': 81, 'learning_rate': 1.5183727065372833e-05}. Best is trial 0 with value: 0.8552.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:36:01,573]\u001b[0m Trial 1 finished with value: 0.852 and parameters: {'n_layers': 1, 'n_units_l0': 65, 'learning_rate': 0.00843583609962644}. Best is trial 0 with value: 0.8552.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:36:43,196]\u001b[0m Trial 2 finished with value: 0.8612 and parameters: {'n_layers': 1, 'n_units_l0': 11, 'learning_rate': 0.0010410458850084682}. Best is trial 2 with value: 0.8612.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:37:24,849]\u001b[0m Trial 3 finished with value: 0.8596 and parameters: {'n_layers': 1, 'n_units_l0': 79, 'learning_rate': 0.0014316121947019827}. Best is trial 2 with value: 0.8612.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:38:00,672]\u001b[0m Trial 4 finished with value: 0.8224 and parameters: {'n_layers': 2, 'n_units_l0': 83, 'n_units_l1': 26, 'learning_rate': 0.0071494262727014035}. Best is trial 2 with value: 0.8612.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:38:42,389]\u001b[0m Trial 5 finished with value: 0.8588 and parameters: {'n_layers': 3, 'n_units_l0': 19, 'n_units_l1': 35, 'n_units_l2': 33, 'learning_rate': 7.192977582626748e-05}. Best is trial 2 with value: 0.8612.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:39:18,027]\u001b[0m Trial 6 finished with value: 0.8636 and parameters: {'n_layers': 3, 'n_units_l0': 12, 'n_units_l1': 7, 'n_units_l2': 14, 'learning_rate': 0.00825290053837357}. Best is trial 6 with value: 0.8636.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:39:50,380]\u001b[0m Trial 7 finished with value: 0.818 and parameters: {'n_layers': 1, 'n_units_l0': 31, 'learning_rate': 1.3752673494869264e-05}. Best is trial 6 with value: 0.8636.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:40:24,846]\u001b[0m Trial 8 finished with value: 0.8644 and parameters: {'n_layers': 2, 'n_units_l0': 23, 'n_units_l1': 4, 'learning_rate': 0.0034817855748954653}. Best is trial 8 with value: 0.8644.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:40:55,160]\u001b[0m Trial 9 finished with value: 0.8012 and parameters: {'n_layers': 2, 'n_units_l0': 14, 'n_units_l1': 8, 'learning_rate': 1.1716352310218521e-05}. Best is trial 8 with value: 0.8644.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:41:37,019]\u001b[0m Trial 10 finished with value: 0.8012 and parameters: {'n_layers': 4, 'n_units_l0': 4, 'n_units_l1': 4, 'n_units_l2': 121, 'n_units_l3': 4, 'learning_rate': 0.0956001235090488}. Best is trial 8 with value: 0.8644.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:42:18,724]\u001b[0m Trial 11 finished with value: 0.8608 and parameters: {'n_layers': 3, 'n_units_l0': 6, 'n_units_l1': 4, 'n_units_l2': 4, 'learning_rate': 0.014224445975026648}. Best is trial 8 with value: 0.8644.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:43:00,519]\u001b[0m Trial 12 finished with value: 0.8588 and parameters: {'n_layers': 3, 'n_units_l0': 9, 'n_units_l1': 10, 'n_units_l2': 28, 'learning_rate': 0.000245778400666313}. Best is trial 8 with value: 0.8644.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:43:42,245]\u001b[0m Trial 13 finished with value: 0.8608 and parameters: {'n_layers': 2, 'n_units_l0': 27, 'n_units_l1': 10, 'learning_rate': 0.03130267486121289}. Best is trial 8 with value: 0.8644.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:44:13,651]\u001b[0m Trial 14 finished with value: 0.864 and parameters: {'n_layers': 3, 'n_units_l0': 16, 'n_units_l1': 6, 'n_units_l2': 10, 'learning_rate': 0.0029747705046498257}. Best is trial 8 with value: 0.8644.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:44:55,295]\u001b[0m Trial 15 finished with value: 0.86 and parameters: {'n_layers': 2, 'n_units_l0': 45, 'n_units_l1': 16, 'learning_rate': 0.00038100234665817197}. Best is trial 8 with value: 0.8644.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:45:28,087]\u001b[0m Trial 16 finished with value: 0.8564 and parameters: {'n_layers': 4, 'n_units_l0': 20, 'n_units_l1': 4, 'n_units_l2': 5, 'n_units_l3': 10, 'learning_rate': 0.002400773897629462}. Best is trial 8 with value: 0.8644.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:46:09,804]\u001b[0m Trial 17 finished with value: 0.8676 and parameters: {'n_layers': 3, 'n_units_l0': 7, 'n_units_l1': 128, 'n_units_l2': 65, 'learning_rate': 0.0028376634936698457}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:46:52,047]\u001b[0m Trial 18 finished with value: 0.8628 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'n_units_l1': 122, 'learning_rate': 0.0003185565599570891}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:47:28,724]\u001b[0m Trial 19 finished with value: 0.8628 and parameters: {'n_layers': 3, 'n_units_l0': 4, 'n_units_l1': 50, 'n_units_l2': 84, 'learning_rate': 0.03251694073619624}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:48:01,496]\u001b[0m Trial 20 finished with value: 0.8464 and parameters: {'n_layers': 2, 'n_units_l0': 6, 'n_units_l1': 15, 'learning_rate': 9.861625809835392e-05}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:48:43,244]\u001b[0m Trial 21 finished with value: 0.8504 and parameters: {'n_layers': 3, 'n_units_l0': 16, 'n_units_l1': 7, 'n_units_l2': 51, 'learning_rate': 0.002777874912451823}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:49:25,040]\u001b[0m Trial 22 finished with value: 0.8504 and parameters: {'n_layers': 3, 'n_units_l0': 119, 'n_units_l1': 6, 'n_units_l2': 16, 'learning_rate': 0.003300933407773996}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:50:06,820]\u001b[0m Trial 23 finished with value: 0.844 and parameters: {'n_layers': 4, 'n_units_l0': 30, 'n_units_l1': 44, 'n_units_l2': 9, 'n_units_l3': 124, 'learning_rate': 0.0005957461596916545}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:50:48,560]\u001b[0m Trial 24 finished with value: 0.8544 and parameters: {'n_layers': 3, 'n_units_l0': 8, 'n_units_l1': 14, 'n_units_l2': 54, 'learning_rate': 0.003553663983466513}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:51:18,677]\u001b[0m Trial 25 finished with value: 0.8588 and parameters: {'n_layers': 2, 'n_units_l0': 10, 'n_units_l1': 5, 'learning_rate': 0.0013082684731336451}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:51:57,314]\u001b[0m Trial 26 finished with value: 0.854 and parameters: {'n_layers': 3, 'n_units_l0': 23, 'n_units_l1': 123, 'n_units_l2': 8, 'learning_rate': 0.018821140148650235}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:52:37,876]\u001b[0m Trial 27 finished with value: 0.84 and parameters: {'n_layers': 4, 'n_units_l0': 15, 'n_units_l1': 78, 'n_units_l2': 22, 'n_units_l3': 28, 'learning_rate': 0.005248611069287853}. Best is trial 17 with value: 0.8676.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:53:19,608]\u001b[0m Trial 28 finished with value: 0.868 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'n_units_l1': 24, 'learning_rate': 0.0020067193095280773}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:54:01,282]\u001b[0m Trial 29 finished with value: 0.8616 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'n_units_l1': 24, 'learning_rate': 0.00014728074462808279}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:54:42,997]\u001b[0m Trial 30 finished with value: 0.8504 and parameters: {'n_layers': 2, 'n_units_l0': 47, 'n_units_l1': 73, 'learning_rate': 0.0006706309907864372}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:55:24,650]\u001b[0m Trial 31 finished with value: 0.8636 and parameters: {'n_layers': 2, 'n_units_l0': 5, 'n_units_l1': 5, 'learning_rate': 0.0017921100154012178}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:56:02,516]\u001b[0m Trial 32 finished with value: 0.8584 and parameters: {'n_layers': 3, 'n_units_l0': 38, 'n_units_l1': 10, 'n_units_l2': 47, 'learning_rate': 3.4278440169278555e-05}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:56:44,190]\u001b[0m Trial 33 finished with value: 0.8648 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'learning_rate': 0.0046454325359530325}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:57:12,715]\u001b[0m Trial 34 finished with value: 0.8616 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'learning_rate': 0.0008590526821569644}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:57:43,946]\u001b[0m Trial 35 finished with value: 0.8664 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'learning_rate': 0.012943442086921907}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:58:15,163]\u001b[0m Trial 36 finished with value: 0.8624 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'learning_rate': 0.0060830140340477155}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:58:44,974]\u001b[0m Trial 37 finished with value: 0.8616 and parameters: {'n_layers': 1, 'n_units_l0': 12, 'learning_rate': 0.012824578626466934}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:59:14,374]\u001b[0m Trial 38 finished with value: 0.8616 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'learning_rate': 0.05371578286910653}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 09:59:43,040]\u001b[0m Trial 39 finished with value: 0.842 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'learning_rate': 0.008357017357906886}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:00:24,714]\u001b[0m Trial 40 finished with value: 0.8648 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'learning_rate': 0.0017538433613564792}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:01:06,407]\u001b[0m Trial 41 finished with value: 0.8664 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'learning_rate': 0.0017726115889855378}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:01:48,104]\u001b[0m Trial 42 finished with value: 0.8632 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'learning_rate': 0.004781829245437053}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:02:17,247]\u001b[0m Trial 43 finished with value: 0.8644 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'learning_rate': 0.0017290982776734924}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:02:46,091]\u001b[0m Trial 44 finished with value: 0.8576 and parameters: {'n_layers': 1, 'n_units_l0': 10, 'learning_rate': 0.01335696612082924}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:03:27,749]\u001b[0m Trial 45 finished with value: 0.8616 and parameters: {'n_layers': 1, 'n_units_l0': 8, 'learning_rate': 0.0010783214182086985}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:04:09,369]\u001b[0m Trial 46 finished with value: 0.8652 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'learning_rate': 0.008739900617143583}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:04:51,083]\u001b[0m Trial 47 finished with value: 0.8492 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'learning_rate': 0.020449997686899857}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:05:20,252]\u001b[0m Trial 48 finished with value: 0.8608 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'learning_rate': 0.009996576064879944}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:05:52,647]\u001b[0m Trial 49 finished with value: 0.848 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'n_units_l1': 56, 'learning_rate': 0.03824113251835159}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:06:21,048]\u001b[0m Trial 50 finished with value: 0.8444 and parameters: {'n_layers': 1, 'n_units_l0': 4, 'learning_rate': 0.007420007745461355}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:07:02,724]\u001b[0m Trial 51 finished with value: 0.86 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'learning_rate': 0.004726151369442947}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:07:44,446]\u001b[0m Trial 52 finished with value: 0.8648 and parameters: {'n_layers': 1, 'n_units_l0': 12, 'learning_rate': 0.0024045219477792077}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:08:13,283]\u001b[0m Trial 53 finished with value: 0.8624 and parameters: {'n_layers': 1, 'n_units_l0': 6, 'learning_rate': 0.0005963073677654659}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:08:54,874]\u001b[0m Trial 54 finished with value: 0.8672 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'learning_rate': 0.020872591704975095}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:09:26,277]\u001b[0m Trial 55 finished with value: 0.852 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'learning_rate': 0.09152188444730364}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:10:07,947]\u001b[0m Trial 56 finished with value: 0.864 and parameters: {'n_layers': 2, 'n_units_l0': 7, 'n_units_l1': 34, 'learning_rate': 0.022436957908612706}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:10:36,734]\u001b[0m Trial 57 finished with value: 0.8592 and parameters: {'n_layers': 1, 'n_units_l0': 5, 'learning_rate': 0.010582366011228502}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:11:13,616]\u001b[0m Trial 58 finished with value: 0.8432 and parameters: {'n_layers': 3, 'n_units_l0': 10, 'n_units_l1': 20, 'n_units_l2': 127, 'learning_rate': 0.05222749558330848}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:11:47,244]\u001b[0m Trial 59 finished with value: 0.8644 and parameters: {'n_layers': 2, 'n_units_l0': 4, 'n_units_l1': 102, 'learning_rate': 0.017310749477202337}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:12:28,857]\u001b[0m Trial 60 finished with value: 0.8652 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'learning_rate': 0.006902423351690187}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:13:00,267]\u001b[0m Trial 61 finished with value: 0.8604 and parameters: {'n_layers': 1, 'n_units_l0': 7, 'learning_rate': 0.0037320496132154145}. Best is trial 28 with value: 0.868.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:13:31,179]\u001b[0m Trial 62 finished with value: 0.8704 and parameters: {'n_layers': 1, 'n_units_l0': 9, 'learning_rate': 0.02699696009932547}. Best is trial 62 with value: 0.8704.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:14:00,953]\u001b[0m Trial 63 finished with value: 0.8728 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'learning_rate': 0.028017599980643935}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:14:32,345]\u001b[0m Trial 64 finished with value: 0.8688 and parameters: {'n_layers': 1, 'n_units_l0': 13, 'learning_rate': 0.032220152278416916}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:15:14,011]\u001b[0m Trial 65 finished with value: 0.8592 and parameters: {'n_layers': 2, 'n_units_l0': 17, 'n_units_l1': 32, 'learning_rate': 0.06149624116489286}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:15:54,181]\u001b[0m Trial 66 finished with value: 0.866 and parameters: {'n_layers': 3, 'n_units_l0': 13, 'n_units_l1': 58, 'n_units_l2': 79, 'learning_rate': 0.029176006827253295}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:16:26,765]\u001b[0m Trial 67 finished with value: 0.8648 and parameters: {'n_layers': 1, 'n_units_l0': 11, 'learning_rate': 0.041325158309052354}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:17:10,306]\u001b[0m Trial 68 finished with value: 0.8588 and parameters: {'n_layers': 4, 'n_units_l0': 9, 'n_units_l1': 93, 'n_units_l2': 77, 'n_units_l3': 30, 'learning_rate': 0.07540961100446969}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:17:51,903]\u001b[0m Trial 69 finished with value: 0.8636 and parameters: {'n_layers': 1, 'n_units_l0': 13, 'learning_rate': 0.024780901078118863}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:18:25,383]\u001b[0m Trial 70 finished with value: 0.8652 and parameters: {'n_layers': 2, 'n_units_l0': 20, 'n_units_l1': 28, 'learning_rate': 0.04107876167322025}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:18:57,320]\u001b[0m Trial 71 finished with value: 0.8608 and parameters: {'n_layers': 1, 'n_units_l0': 11, 'learning_rate': 0.015511678518696797}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:19:28,926]\u001b[0m Trial 72 finished with value: 0.8668 and parameters: {'n_layers': 1, 'n_units_l0': 17, 'learning_rate': 0.029068988796475282}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:19:58,045]\u001b[0m Trial 73 finished with value: 0.8688 and parameters: {'n_layers': 1, 'n_units_l0': 18, 'learning_rate': 0.027351282513850078}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:20:30,129]\u001b[0m Trial 74 finished with value: 0.8612 and parameters: {'n_layers': 1, 'n_units_l0': 23, 'learning_rate': 0.025410845889709092}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:21:02,276]\u001b[0m Trial 75 finished with value: 0.8588 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'learning_rate': 0.03157103149727367}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:21:34,008]\u001b[0m Trial 76 finished with value: 0.8652 and parameters: {'n_layers': 1, 'n_units_l0': 27, 'learning_rate': 0.0676923976889936}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:22:10,060]\u001b[0m Trial 77 finished with value: 0.8628 and parameters: {'n_layers': 3, 'n_units_l0': 18, 'n_units_l1': 41, 'n_units_l2': 38, 'learning_rate': 0.04798088007265111}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:22:41,635]\u001b[0m Trial 78 finished with value: 0.868 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'learning_rate': 0.01911059958111978}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:23:23,774]\u001b[0m Trial 79 finished with value: 0.8716 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'learning_rate': 0.019304667056548062}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:23:53,278]\u001b[0m Trial 80 finished with value: 0.8688 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'learning_rate': 0.015848310528621873}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:24:34,922]\u001b[0m Trial 81 finished with value: 0.8644 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'learning_rate': 0.016852854518770263}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:25:16,615]\u001b[0m Trial 82 finished with value: 0.8704 and parameters: {'n_layers': 1, 'n_units_l0': 22, 'learning_rate': 0.010880874659094725}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:25:58,235]\u001b[0m Trial 83 finished with value: 0.87 and parameters: {'n_layers': 1, 'n_units_l0': 22, 'learning_rate': 0.01205766038073835}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:26:39,959]\u001b[0m Trial 84 finished with value: 0.8656 and parameters: {'n_layers': 1, 'n_units_l0': 23, 'learning_rate': 0.010295539803424859}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:27:21,628]\u001b[0m Trial 85 finished with value: 0.8584 and parameters: {'n_layers': 1, 'n_units_l0': 19, 'learning_rate': 0.03932246850646985}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:27:52,990]\u001b[0m Trial 86 finished with value: 0.8676 and parameters: {'n_layers': 1, 'n_units_l0': 25, 'learning_rate': 0.012586827454783032}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:28:34,654]\u001b[0m Trial 87 finished with value: 0.8644 and parameters: {'n_layers': 1, 'n_units_l0': 35, 'learning_rate': 0.026732580194066664}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:29:16,349]\u001b[0m Trial 88 finished with value: 0.8136 and parameters: {'n_layers': 1, 'n_units_l0': 20, 'learning_rate': 3.0419182028797507e-05}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:29:47,200]\u001b[0m Trial 89 finished with value: 0.864 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'learning_rate': 0.019457759305114147}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:30:28,861]\u001b[0m Trial 90 finished with value: 0.8668 and parameters: {'n_layers': 1, 'n_units_l0': 30, 'learning_rate': 0.03474763944394244}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:31:10,577]\u001b[0m Trial 91 finished with value: 0.8664 and parameters: {'n_layers': 1, 'n_units_l0': 21, 'learning_rate': 0.015184264605709789}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:31:39,504]\u001b[0m Trial 92 finished with value: 0.8668 and parameters: {'n_layers': 1, 'n_units_l0': 16, 'learning_rate': 0.011968762487340603}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:32:21,100]\u001b[0m Trial 93 finished with value: 0.8728 and parameters: {'n_layers': 1, 'n_units_l0': 14, 'learning_rate': 0.02184671431372838}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:32:52,514]\u001b[0m Trial 94 finished with value: 0.86 and parameters: {'n_layers': 1, 'n_units_l0': 13, 'learning_rate': 0.022006602131909105}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:33:34,571]\u001b[0m Trial 95 finished with value: 0.8568 and parameters: {'n_layers': 1, 'n_units_l0': 11, 'learning_rate': 0.005936495735663538}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:34:16,198]\u001b[0m Trial 96 finished with value: 0.87 and parameters: {'n_layers': 1, 'n_units_l0': 26, 'learning_rate': 0.008938543194185111}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:34:57,827]\u001b[0m Trial 97 finished with value: 0.8612 and parameters: {'n_layers': 1, 'n_units_l0': 27, 'learning_rate': 0.009047457582571708}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:35:27,193]\u001b[0m Trial 98 finished with value: 0.8644 and parameters: {'n_layers': 1, 'n_units_l0': 18, 'learning_rate': 0.046705782993626745}. Best is trial 63 with value: 0.8728.\u001b[0m\n",
            "\u001b[32m[I 2022-04-06 10:36:04,992]\u001b[0m Trial 99 finished with value: 0.8672 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'learning_rate': 0.016481472405652904}. Best is trial 63 with value: 0.8728.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NN with Optuna Tuner\n",
        "# Take the results\n",
        "lr, n_layers, n_units = list(study.best_trial.params.values())\n",
        "# Building the model\n",
        "model = tf.keras.models.Sequential()\n",
        "for layer in range(n_layers):\n",
        "  model.add(F.Dense(units = n_units, activation = 'relu'))\n",
        "\n",
        "model.add(F.Dense(units = 1, activation = 'sigmoid')) # Output layer\n",
        "\n",
        "# Training the model\n",
        "model.compile(optimizer = tf.optimizers.Adam(learning_rate = lr), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size = 32, epochs = 100, verbose = 0)\n",
        "\n",
        "# Predicting the test values\n",
        "y_pred = np.rint(model.predict(X_test))\n",
        "\n",
        "# f1 score and accuracy of predictions\n",
        "score['NN tuned'] = [f1_score(y_test, y_pred), \n",
        "                 accuracy_score(y_test, y_pred)]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EzKJRpu4l1aR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Results\n",
        "result = pd.DataFrame(score.values(), columns = ['f1 score', 'Accuracy'], \n",
        "                      index = score.keys())\n",
        "result.style"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "cellView": "form",
        "id": "QENpzZydeB9J",
        "outputId": "855430dc-1e31-4580-d918-9d63475568be"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ff43b159350>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_ca2d2_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >f1 score</th>\n",
              "      <th class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_ca2d2_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
              "      <td id=\"T_ca2d2_row0_col0\" class=\"data row0 col0\" >0.2891</td>\n",
              "      <td id=\"T_ca2d2_row0_col1\" class=\"data row0 col1\" >0.8072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ca2d2_level0_row1\" class=\"row_heading level0 row1\" >K-Nearest Neighbors</th>\n",
              "      <td id=\"T_ca2d2_row1_col0\" class=\"data row1 col0\" >0.4619</td>\n",
              "      <td id=\"T_ca2d2_row1_col1\" class=\"data row1 col1\" >0.8304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ca2d2_level0_row2\" class=\"row_heading level0 row2\" >Support Vector Machine</th>\n",
              "      <td id=\"T_ca2d2_row2_col0\" class=\"data row2 col0\" >0.0000</td>\n",
              "      <td id=\"T_ca2d2_row2_col1\" class=\"data row2 col1\" >0.8012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ca2d2_level0_row3\" class=\"row_heading level0 row3\" >Kernel SVM</th>\n",
              "      <td id=\"T_ca2d2_row3_col0\" class=\"data row3 col0\" >0.5182</td>\n",
              "      <td id=\"T_ca2d2_row3_col1\" class=\"data row3 col1\" >0.8572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ca2d2_level0_row4\" class=\"row_heading level0 row4\" >Naive Bayes</th>\n",
              "      <td id=\"T_ca2d2_row4_col0\" class=\"data row4 col0\" >0.4709</td>\n",
              "      <td id=\"T_ca2d2_row4_col1\" class=\"data row4 col1\" >0.8256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ca2d2_level0_row5\" class=\"row_heading level0 row5\" >Decision Tree</th>\n",
              "      <td id=\"T_ca2d2_row5_col0\" class=\"data row5 col0\" >0.5134</td>\n",
              "      <td id=\"T_ca2d2_row5_col1\" class=\"data row5 col1\" >0.7968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ca2d2_level0_row6\" class=\"row_heading level0 row6\" >Random Forest</th>\n",
              "      <td id=\"T_ca2d2_row6_col0\" class=\"data row6 col0\" >0.5829</td>\n",
              "      <td id=\"T_ca2d2_row6_col1\" class=\"data row6 col1\" >0.8672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ca2d2_level0_row7\" class=\"row_heading level0 row7\" >NN normal</th>\n",
              "      <td id=\"T_ca2d2_row7_col0\" class=\"data row7 col0\" >0.5711</td>\n",
              "      <td id=\"T_ca2d2_row7_col1\" class=\"data row7 col1\" >0.8624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ca2d2_level0_row8\" class=\"row_heading level0 row8\" >NN tuned</th>\n",
              "      <td id=\"T_ca2d2_row8_col0\" class=\"data row8 col0\" >0.0000</td>\n",
              "      <td id=\"T_ca2d2_row8_col1\" class=\"data row8 col1\" >0.8012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}